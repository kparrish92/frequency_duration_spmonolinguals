read.csv("./lexicalfrequencydata/1CUETOS-APENDICE-Subtlex-Esp.xlsx")
data = read.csv("./lexicalfrequencydata/1CUETOS-APENDICE-Subtlex-Esp.xlsx")
data = read.csv("./lexicalfrequencydata/corpus.csv")
View(data)
View(data)
View(data)
View(data)
glimpse(data)
rse)
library(dplyr)
library(tidyverse)
data = read.csv("./lexicalfrequencydata/corpus.csv")
glimpse(data)
library(dplyr)
glimpse(data)
data %>%
pivot_longer(c,`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word")
data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word")
library(tidyverse)
library(dplyr)
data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word")
X = data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word")
View(X)
View(data)
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word") %>%
pivot_longer(c(`Freq..count`,`Freq..count.1`, `Freq..count.2`), names_to = "trash2", values_to "freq_count")
View(X)
X = data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word") %>%
pivot_longer(c(`Freq..count`,`Freq..count.1`,`Freq..count.2`), names_to = "trash2", values_to "freq_count")
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word") %>%
pivot_longer(c(`Freq..count.1`,`Freq..count.2`,`Freq..count`), names_to = "trash2", values_to = "freq_count")
### This is a script to derive stimuli grouped by lexical frequency based on the data
### made available by Ceutos et al. (2011). They estimat Spanish word frequencies based on
### data from movie subtitles. The mansucript for this study can by found in the repo under
### 'previous_studies', and their data under 'lexical frequency data'
## Load libraries
library(tidyverse)
library(dplyr)
## Read in data
data = read.csv("./lexicalfrequencydata/corpus.csv")
## Pivot from wide to long
glimpse(data)
data$Freq..count.1
X = data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word") %>%
pivot_longer(c(`Freq..count.1`,`Freq..count.2`,`Freq..count`), names_to = "trash2", values_to = "freq_count")
View(X)
View(data)
data = read.csv("./lexicalfrequencydata/corpus.csv")
## Pivot from wide to long
glimpse(data)
data$freq
X = data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word") %>%
pivot_longer(c(`Freq..count.1`,`Freq..count.2`,`Freq..count`), names_to = "trash2", values_to = "freq_count") %>%
pivot_longer(c(`Log.freq.`,`Log.freq.1`,`Log.freq.2`), names_to = "trash3", values_to = "freq_per_million") %>%
pivot_longer(c(`Freq..per.million`,`Freq..per.million.1`,`Freq..p
X = data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word") %>%
pivot_longer(c(`Freq..count.1`,`Freq..count.2`,`Freq..count`), names_to = "trash2", values_to = "freq_count") %>%
pivot_longer(c(`Log.freq.`,`Log.freq.1`,`Log.freq.2`), names_to = "trash3", values_to = "freq_per_million") %>%
pivot_longer(c(`Freq..per.million`,`Freq..per.million.1`,`Freq..per.million.2`), names_to = "trash4", values_to = "log_freq")
View(data)
X = data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word") %>%
pivot_longer(c(`Freq..count.1`,`Freq..count.2`,`Freq..count`), names_to = "trash2", values_to = "freq_count") %>%
pivot_longer(c(`Log.freq.`,`Log.freq.1`,`Log.freq.2`), names_to = "trash3", values_to = "freq_per_million") %>%
pivot_longer(c(`Freq..per.million`,`Freq..per.million.1`,`Freq..per.million.2`), names_to = "trash4", values_to = "log_freq")
View(data)
data = read.csv("./lexicalfrequencydata/corpus.csv")
## Pivot from wide to long
X = data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word") %>%
pivot_longer(c(`Freq..count.1`,`Freq..count.2`,`Freq..count`), names_to = "trash2", values_to = "freq_count") %>%
pivot_longer(c(`Log.freq.`,`Log.freq.1`,`Log.freq.2`), names_to = "trash3", values_to = "freq_per_million") %>%
pivot_longer(c(`Freq..per.million`,`Freq..per.million.1`,`Freq..per.million.2`), names_to = "trash4", values_to = "log_freq")
View(data)
X = data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word") %>%
pivot_longer(c(`Freq..count.1`,`Freq..count.2`,`Freq..count`), names_to = "trash2", values_to = "freq_count")
View(X)
data = read.csv("./lexicalfrequencydata/corpus.csv")
## Pivot from wide to long
X = data %>%
pivot_longer(c(`ï..Word`,`Word`,`Word.1`), names_to = "trash", values_to = "word")
View(X)
data = read.csv("./lexicalfrequencydata/corpus.csv")
View(data)
data %>%
filter(nchar == 8)
library(tidyverse)
library(dplyr)
data %>%
filter(nchar == 8)
data %>%
filter(nchar(as.character(ï..Word)) == 6)
data = data %>%
janitor::clean_names()
View(data)
View(data)
data = data %>%
janitor::clean_names() %>%
filter(nchar(as.character(i_Word)) == 6)
data = data %>%
janitor::clean_names() %>%
filter(nchar(as.character(i_word)) == 6)
View(data)
six_letterwords = data %>%
janitor::clean_names() %>%
filter(nchar(as.character(i_word)) == 6)
View(data)
hist(six_letterwords$freq_count)
hist(six_letterwords$log_freq)
library(languageR)
library(tidyverse)
library(dplyr)
library(languageR)
Spanish = Spanish
Spanish = spanish
View(Spanish)
Spanish = spanishMeta
View(Spanish)
data = read.csv("./lexicalfrequencydata/corpus.csv")
## tidy data and visualize the distribution of log frequency
six_letterwords = data %>%
janitor::clean_names() %>%
filter(nchar(as.character(i_word)) == 6)
hist(six_letterwords$log_freq)
library(tidyverse)
library(dplyr)
library(languageR)
## Read in data
data = read.csv("./lexicalfrequencydata/corpus.csv")
## tidy data and visualize the distribution of log frequency
six_letterwords = data %>%
janitor::clean_names() %>%
filter(nchar(as.character(i_word)) == 6)
hist(six_letterwords$log_freq)
View(six_letterwords)
